{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AraMeter.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0bada02/Academic-Management-System/blob/main/MetRec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d0vjDuxuHl8",
        "outputId": "78d7ad0d-d070-4e65-aa41-46d0afab202e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyarabic"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarabic in /usr/local/lib/python3.10/dist-packages (0.6.15)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from pyarabic) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Klf1-MC3DEhi"
      },
      "source": [
        "We use a product review dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvOJw5Bg6c5J",
        "outputId": "678ed22d-4363-4e92-98e7-ae2e948c0c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget 'https://raw.githubusercontent.com/zaidalyafeai/ARBML/master/datasets/Poem Meters/baits.zip'\n",
        "!unzip baits.zip"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-12 18:28:06--  https://raw.githubusercontent.com/zaidalyafeai/ARBML/master/datasets/Poem%20Meters/baits.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2267882 (2.2M) [application/zip]\n",
            "Saving to: ‘baits.zip.3’\n",
            "\n",
            "baits.zip.3         100%[===================>]   2.16M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-11-12 18:28:07 (145 MB/s) - ‘baits.zip.3’ saved [2267882/2267882]\n",
            "\n",
            "Archive:  baits.zip\n",
            "replace final_baits/train.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: final_baits/train.txt   \n",
            "replace final_baits/labels.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: final_baits/labels.txt  \n",
            "replace final_baits/test.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: final_baits/test.txt    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwlvjSR-DS15"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23FSFg5t6fc1"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "from random import shuffle\n",
        "from pyarabic import araby\n",
        "from tensorflow.keras.layers import GRU, Embedding, Dense, Input, Dropout, Bidirectional, BatchNormalization, Flatten, Reshape\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZEFvXv2SqUg"
      },
      "source": [
        "with open('final_baits/labels.txt', 'r') as f:\n",
        "  label2name = f.readlines()\n",
        "  label2name = [name.replace('\\n', '') for name in label2name]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfbnvdT4Cmz0"
      },
      "source": [
        "## Read the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKhqB_MfCjEP"
      },
      "source": [
        "preprocess a review by removing special characters and long spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7MjMLLn6gtK"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "def extract_data(path, thresh = 70, on_shatrs = False):\n",
        "  global vocab\n",
        "\n",
        "  text = \"\"\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "\n",
        "  t = open(path, 'r').read()\n",
        "  t = araby.strip_tashkeel(t)\n",
        "\n",
        "  # remove some exteranous chars\n",
        "  execluded = '!()*-ـ.:=o[]«»;؛,،~?؟\\u200f\\ufeffـ'\n",
        "  out = \"\"\n",
        "\n",
        "  for char in t:\n",
        "    if char not in execluded:\n",
        "      out += char\n",
        "\n",
        "  text += out\n",
        "  baits = out.split('\\n')\n",
        "  for line in baits:\n",
        "    if len(line) <= 1:\n",
        "      continue\n",
        "    label, bait = line.split(' ', 1)\n",
        "    label = int(label)\n",
        "\n",
        "    bait  = bait.strip()\n",
        "    if on_shatrs:\n",
        "      shatrs = bait.split('#')\n",
        "      for shatr in shatrs:\n",
        "        X.append(shatr.strip())\n",
        "        y.append(label)\n",
        "    else:\n",
        "      X.append(bait.strip())\n",
        "      y.append(label)\n",
        "\n",
        "  #create the vocab\n",
        "  vocab = sorted(set(' '.join(X)))\n",
        "\n",
        "  #shuffle the data\n",
        "  X, y = shuffle(X, y)\n",
        "  return X, y"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWwTc-z2fv69"
      },
      "source": [
        "X, y = extract_data(\"final_baits/train.txt\", on_shatrs=False)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7oXawNaVyEL",
        "outputId": "69f1f56c-1369-4739-d117-2c8a1ad0f55b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(5):\n",
        "  print(X[i], ' ', label2name[y[i]])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "يبليك من ذكر بعد النوى وبلي # ووافقتك الأماني وهي باطلة   baseet\n",
            "أوثقته من الذنوب ديون # شددت في اقتضائها الغرماء   khafeef\n",
            "وتفرغ أنواع الفروغ صوادقا # دلاء لها منهلة كالسحائب   taweel\n",
            "قد يرى حبها الأهلة وجدا # فأطالت على الضلوع انحناها   khafeef\n",
            "وقد شبت مما قذفت به # بإثر اثنتين وعشرين عام   mutakareb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syg_fvtnC1AK"
      },
      "source": [
        "## Create Sequences\n",
        "Create sequences by using the most repeated 500 words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq0Ber9ICcWb"
      },
      "source": [
        "## Create Numpy Arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROef8aerf8ar"
      },
      "source": [
        "X_train, X_valid , y_train, y_valid = train_test_split(X, y, test_size = 0.15, random_state = 41)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63NiojywQ18F"
      },
      "source": [
        "# Creating a mapping from unique characters to indices\n",
        "char2idx = {u:i+1 for i, u in enumerate(vocab)}\n",
        "\n",
        "def to_sequences(X):\n",
        "  X = [[char2idx[char] for char in line] for line in X]\n",
        "  X = pad_sequences(X, padding='post', value=0, maxlen = 100)\n",
        "  return X\n",
        "\n",
        "X_train = to_sequences(X_train)\n",
        "X_valid = to_sequences(X_valid)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_valid = np.array(y_valid)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uHdRK4cCrGJ"
      },
      "source": [
        "## Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3u3OxEcBfJ2"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Input((100,)))\n",
        "model.add(Embedding(len(char2idx)+1, 256))\n",
        "model.add(Bidirectional(GRU(units = 256, return_sequences=True)))\n",
        "model.add(Bidirectional(GRU(units = 256, return_sequences=True)))\n",
        "model.add(Bidirectional(GRU(units = 256)))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(label2name), activation = 'softmax'))\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7imJBjJHxK1-",
        "outputId": "f91b39ef-f6e2-4cfd-d24b-bcf7a5884f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │           \u001b[38;5;34m9,984\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_9 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m789,504\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m1,182,720\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,182,720\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)                  │           \u001b[38;5;34m1,806\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,984</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">789,504</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,182,720</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,806</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,232,398\u001b[0m (12.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,232,398</span> (12.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,232,398\u001b[0m (12.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,232,398</span> (12.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPyUsGe_u9tw",
        "outputId": "d8a99e93-1a87-422f-e06b-34a930599b58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model(tf.zeros((10, 100))).shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-7U36aDCtQu"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEHRYgLhkozM"
      },
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_delta=0.0001, min_lr=0.0001),\n",
        "    tf.keras.callbacks.ModelCheckpoint('full_verse.keras', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Ew-5ZyC3Nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e443cc70-f1e9-4ea8-f74a-3cf68b378ee3"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data= (X_valid, y_valid), epochs = 15, batch_size= 128, shuffle = True, callbacks=callbacks)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1577 - loss: 2.3650\n",
            "Epoch 1: val_accuracy improved from -inf to 0.39992, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 125ms/step - accuracy: 0.1579 - loss: 2.3641 - val_accuracy: 0.3999 - val_loss: 1.6681 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.4741 - loss: 1.4899\n",
            "Epoch 2: val_accuracy improved from 0.39992 to 0.76220, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 123ms/step - accuracy: 0.4744 - loss: 1.4892 - val_accuracy: 0.7622 - val_loss: 0.7370 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.7798 - loss: 0.7093\n",
            "Epoch 3: val_accuracy improved from 0.76220 to 0.84849, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 120ms/step - accuracy: 0.7799 - loss: 0.7091 - val_accuracy: 0.8485 - val_loss: 0.4937 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8651 - loss: 0.4493\n",
            "Epoch 4: val_accuracy improved from 0.84849 to 0.89008, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.8652 - loss: 0.4492 - val_accuracy: 0.8901 - val_loss: 0.3699 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9066 - loss: 0.3237\n",
            "Epoch 5: val_accuracy did not improve from 0.89008\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 119ms/step - accuracy: 0.9066 - loss: 0.3237 - val_accuracy: 0.8899 - val_loss: 0.3732 - learning_rate: 0.0010\n",
            "Epoch 6/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9288 - loss: 0.2591\n",
            "Epoch 6: val_accuracy improved from 0.89008 to 0.91017, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.9288 - loss: 0.2591 - val_accuracy: 0.9102 - val_loss: 0.3302 - learning_rate: 0.0010\n",
            "Epoch 7/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.9432 - loss: 0.2100\n",
            "Epoch 7: val_accuracy improved from 0.91017 to 0.92403, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 123ms/step - accuracy: 0.9432 - loss: 0.2100 - val_accuracy: 0.9240 - val_loss: 0.2854 - learning_rate: 0.0010\n",
            "Epoch 8/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9552 - loss: 0.1640\n",
            "Epoch 8: val_accuracy did not improve from 0.92403\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 121ms/step - accuracy: 0.9552 - loss: 0.1640 - val_accuracy: 0.9052 - val_loss: 0.3365 - learning_rate: 0.0010\n",
            "Epoch 9/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9556 - loss: 0.1644\n",
            "Epoch 9: val_accuracy did not improve from 0.92403\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 119ms/step - accuracy: 0.9556 - loss: 0.1644 - val_accuracy: 0.9208 - val_loss: 0.3125 - learning_rate: 0.0010\n",
            "Epoch 10/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9774 - loss: 0.0912\n",
            "Epoch 10: val_accuracy improved from 0.92403 to 0.93012, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 120ms/step - accuracy: 0.9774 - loss: 0.0912 - val_accuracy: 0.9301 - val_loss: 0.2795 - learning_rate: 1.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9847 - loss: 0.0651\n",
            "Epoch 11: val_accuracy did not improve from 0.93012\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 119ms/step - accuracy: 0.9847 - loss: 0.0651 - val_accuracy: 0.9300 - val_loss: 0.2932 - learning_rate: 1.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9867 - loss: 0.0572\n",
            "Epoch 12: val_accuracy improved from 0.93012 to 0.93068, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.9867 - loss: 0.0572 - val_accuracy: 0.9307 - val_loss: 0.2945 - learning_rate: 1.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9895 - loss: 0.0468\n",
            "Epoch 13: val_accuracy improved from 0.93068 to 0.93111, saving model to full_verse.keras\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 120ms/step - accuracy: 0.9895 - loss: 0.0468 - val_accuracy: 0.9311 - val_loss: 0.3007 - learning_rate: 1.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9909 - loss: 0.0368\n",
            "Epoch 14: val_accuracy did not improve from 0.93111\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 119ms/step - accuracy: 0.9909 - loss: 0.0368 - val_accuracy: 0.9307 - val_loss: 0.3136 - learning_rate: 1.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.9924 - loss: 0.0332\n",
            "Epoch 15: val_accuracy did not improve from 0.93111\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 119ms/step - accuracy: 0.9924 - loss: 0.0332 - val_accuracy: 0.9305 - val_loss: 0.3200 - learning_rate: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b2a5eddbf10>"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVnnbxyUgDQ_"
      },
      "source": [
        "model = tf.keras.models.load_model('full_verse.keras')"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwZQrxhdDV4r"
      },
      "source": [
        "## Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q-Texz3DQsH"
      },
      "source": [
        "# def classify(sentence):\n",
        "# # sentence = process_review(sentence)\n",
        "#   sentence = araby.strip_tashkeel(sentence)\n",
        "#   sequence = [char2idx[char] for char in sentence]\n",
        "#   sequence = pad_sequences([sequence], maxlen = X_train.shape[1], padding='post', value=0)\n",
        "\n",
        "#   pred = model.predict(sequence)[0]\n",
        "#   print(label2name[np.argmax(pred, 0).astype('int')], np.max(pred))\n",
        "\n",
        "# def classify(sentence, model_tashkeel, tokenizer):\n",
        "#     # Remove tashkeel initially\n",
        "#     sentence = araby.strip_tashkeel(sentence)\n",
        "\n",
        "#     # Use vocalize_text function to add tashkeel to the sentence\n",
        "#     sentence = vocalize_text(sentence, model_tashkeel, tokenizer)\n",
        "\n",
        "#     # Convert the vocalized sentence to sequences\n",
        "#     sequence = [char2idx.get(char, 0) for char in sentence]\n",
        "#     sequence = pad_sequences([sequence], maxlen=X_train.shape[1], padding='post', value=0)\n",
        "\n",
        "#     # Predict the meter class for the sentence\n",
        "#     pred = model.predict(sequence)[0]\n",
        "#     print(label2name[np.argmax(pred, 0).astype('int')], np.max(pred))\n",
        "\n",
        "def classify(sentence):\n",
        "    # Convert the sentence to sequences\n",
        "    sequence = [char2idx.get(char, 0) for char in sentence]\n",
        "    sequence = pad_sequences([sequence], maxlen=X_train.shape[1], padding='post', value=0)\n",
        "\n",
        "    # Predict the meter class for the sentence\n",
        "    pred = model.predict(sequence)[0]\n",
        "    print(label2name[np.argmax(pred, 0).astype('int')], np.max(pred))\n",
        ""
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMgcfGkZRLF2",
        "outputId": "49b0ff81-da11-4379-f673-303d29fdc690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "classify(\"ما تردون على هذا المحب # دائبا يشكو إليكم في الكتب\")\n",
        "classify(\"ولد الهدى فالكائنات ضياء # وفم الزمان تبسم وسناء\")\n",
        "classify(\" لك يا منازل في القلوب منازل # أقفرت أنت وهن منك أواهل\")\n",
        "classify(\"ومن لم يمت بالسيف مات بغيره # تعددت الأسباب والموت واحد\")\n",
        "classify(\"أنا النبي لا كذب # أنا ابن عبد المطلب\")\n",
        "classify(\"هذه دراهم اقفرت # أم ربور محتها الدهور\")\n",
        "classify(\"هزجنا في بواديكم # فأجزلتم عطايانا\")\n",
        "classify(\"بحر سريع ماله ساحل # مستفعلن مستفعلن فاعلن\")\n",
        "classify(\"مَا مَضَى فَاتَ وَالْمُؤَمَّلُ غَيْبٌ # وَلَكَ السَّاعَةُ الَّتِيْ أَنْتَ فِيْهَا\")\n",
        "classify(\"يا ليلُ الصبّ متى غدهُ # أقيامُ الساعة موعدهُ\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "ramal 0.9997578\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "kamel 0.9817662\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "kamel 0.99513716\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "taweel 0.9993303\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "mujtath 0.49932346\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "rajaz 0.7752931\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "hazaj 0.964103\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "rajaz 0.664896\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "khafeef 0.99997747\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
            "mutadarak 0.9999447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0C1vwNk1du8",
        "outputId": "3173a15b-25d7-4213-b68e-07f96ca8f567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!zip model.zip full_verse.h5"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tzip warning: name not matched: full_verse.h5\n",
            "\n",
            "zip error: Nothing to do! (model.zip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ_Qh6OI1qP5",
        "outputId": "b40c6646-1c9e-4364-873f-33c40b7123e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 46832\n",
            "-rw-r--r-- 1 root root  2267882 Nov 12 17:51 baits.zip\n",
            "-rw-r--r-- 1 root root  2267882 Nov 12 17:57 baits.zip.1\n",
            "-rw-r--r-- 1 root root  2267882 Nov 12 17:59 baits.zip.2\n",
            "-rw-r--r-- 1 root root  2267882 Nov 12 18:28 baits.zip.3\n",
            "drwxr-xr-x 2 root root     4096 Nov 12 18:28 final_baits\n",
            "-rw-r--r-- 1 root root 38867209 Nov 12 18:37 full_verse.keras\n",
            "drwxr-xr-x 1 root root     4096 Nov 11 14:21 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRYJoGMd1q1V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf6bee6-2dd9-4b48-fd24-0e8ff29e2347"
      },
      "source": [
        "classify(\"حِصاني كانَ دَلّالَ المَنايا # فَخاضَ غُبارَها وَشَرى وَباعا\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "wafer 0.9576039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "model_path = \"Abdou/arabic-tashkeel-flan-t5-small\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model_tashkeel = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "NJ9vQmB7l2nI"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vocalize_text(text, model_tashkeel, tokenizer, max_length=256, num_beams=4, temperature=0.2, do_sample=False):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model_tashkeel.to(device)\n",
        "    model_tashkeel.eval()\n",
        "    # Tokenize the input text\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=\"max_length\")\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        if do_sample:\n",
        "            outputs = model_tashkeel.generate(\n",
        "                **inputs,\n",
        "                max_length=max_length,\n",
        "                do_sample=True,\n",
        "                temperature=temperature,\n",
        "            )\n",
        "        else:\n",
        "            outputs = model_tashkeel.generate(\n",
        "                **inputs,\n",
        "                max_length=max_length,\n",
        "                num_beams=num_beams,\n",
        "                early_stopping=True\n",
        "            )\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "b3SF9DGqmUoQ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quran texts\n",
        "quran_texts = [\n",
        "    \"قل هو نبأ عظيم أنتم عنه معرضون\",\n",
        "    \"إنما يخشى الله من عباده العلماء\",\n",
        "    \"والله غالب على أمره ولكن أكثر الناس لا يعلمون\",\n",
        "    \"وعلم ءادم الأسماء كلها ثم عرضهم على الملائكة فقال أنبؤوني بأسماء هؤلاء إن كنتم صادقين\",\n",
        "    \"وإذ قال موسى لقومه يا قوم لم تؤذونني وقد تعلمون أني رسول الله إليكم\",\n",
        "    \"ولله يسجد ما في السماوات وما في الارض من دابة والملاءكة وهم لا يستكبرون\",\n",
        "    \"الذي أحسن كل شيء خلقه وبدأ خلق الإنسان من طين\",\n",
        "]\n",
        "# Hadith texts\n",
        "hadith_texts = [\n",
        "    \"إن الله لا ينظر إلى صوركم وأموالكم ولكن ينظر إلى قلوبكم وأعمالكم\",\n",
        "    \"عن أبي ذر جندب بن جنادة، وأبي عبدالرحمن معاذ بن جبل رضي الله عنهما، عن رسول الله ﷺ، قال: اتق الله حيثما كنت وأتبع السيئة الحسنة تمحها، وخالق الناس بخلق حسن . رواه الترمذي وقال: حديث حسن.\",\n",
        "    \"المسلم من سلم المسلمون من لسانه ويده\",\n",
        "    \"المؤمن القوي خير وأحب إلى الله من المؤمن الضعيف ، وفي كل خير.\",\n",
        "]\n",
        "# some Arabic texts\n",
        "arabic_texts = [\n",
        "    \"إنما الأمم الأخلاق ما بقيت فإن هم ذهبت أخلاقهم ذهبوا\",\n",
        "    \"يعد من أكبر علماء الأندلس وأكبر علماء الإسلام تصنيفًا وتأليفًا بعد الطبري، وهو إمام حافظ. فقيه ظاهري، ومجدد القول به، بل محيي المذهب بعد زواله في الشرق. ومتكلم وأديب وشاعر ونسّابة وعالم برجال الحديث وناقد محلل بل وصفه البعض بالفيلسوف كما عد من أوائل من قال بكروية الأرض، كما كان وزير سياسي لبني أمية، سلك طريق نبذ التقليد وتحرير الأتباع، قامت عليه جماعة من المالكية وشـُرد عن وطنه. توفي لاحقاً في منزله في أرض أبويه منت ليشم المعروفة بمونتيخار حالياً، وهي عزبة قريبة من ولبة. وأصل جده يزيد فارسي، أسلم وأول من دخل منهم بلاد المغرب، وكانت بلدهم قرطبة فولد ابن حزم بها في سلخ نهاية رمضان من سنة أربع وثمانين وثلاثمائة.\"\n",
        "]\n",
        "\n",
        "texts = [\n",
        "    (\"Quran Texts\", quran_texts),\n",
        "    (\"Hadith Texts\", hadith_texts),\n",
        "    (\"Arabic Texts\", arabic_texts)\n",
        "]\n",
        "\n",
        "for title, texts in texts:\n",
        "    print(f\"=============== {title} ===============\")\n",
        "    for text in texts:\n",
        "        vocalized_result = vocalize_text(text, model_tashkeel, tokenizer)\n",
        "        print(f\"Input: \\n{text}\")\n",
        "        print(\"=\"*10)\n",
        "        print(f\"Prediction: \\n{vocalized_result}\")\n",
        "        print(\"=\"*10)"
      ],
      "metadata": {
        "id": "9t5eCV9Umm8Z",
        "outputId": "5d709e6e-e496-4c67-b960-a5539798b8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============== Quran Texts ===============\n",
            "Input: \n",
            "قل هو نبأ عظيم أنتم عنه معرضون\n",
            "==========\n",
            "Prediction: \n",
            "قُلْ هُوَ نَبَأٌ عَظِيمٌ أَنْتُمْ عَنْهُ مُعْرِضُونَ\n",
            "==========\n",
            "Input: \n",
            "إنما يخشى الله من عباده العلماء\n",
            "==========\n",
            "Prediction: \n",
            "إِنَّمَا يَخْشَى ٱللَّهَ مِنْ عِبَادِهِ ٱلْعُلَمَآءُ\n",
            "==========\n",
            "Input: \n",
            "والله غالب على أمره ولكن أكثر الناس لا يعلمون\n",
            "==========\n",
            "Prediction: \n",
            "وَٱللَّهُ غَالِبٌ عَلَىٰٓ أَمْرِهِۦ وَلَٰكِنَّ أَكْثَرَ ٱلنَّاسِ لَا يَعْلَمُونَ\n",
            "==========\n",
            "Input: \n",
            "وعلم ءادم الأسماء كلها ثم عرضهم على الملائكة فقال أنبؤوني بأسماء هؤلاء إن كنتم صادقين\n",
            "==========\n",
            "Prediction: \n",
            "وَعَلِّمْ ءَادَمَ ٱلْأَسْمَآءَ كُلَّهَا ثُمَّ عَرَضَهُمْ عَلَى ٱلْمَلاَئِكَةِ فَقَالَ أَنبَؤُونِي بِأَسْمَاءِ هَٰٓؤُلَآءِ إِن كُنتُمْ صَادِقِينَ\n",
            "==========\n",
            "Input: \n",
            "وإذ قال موسى لقومه يا قوم لم تؤذونني وقد تعلمون أني رسول الله إليكم\n",
            "==========\n",
            "Prediction: \n",
            "وَإِذْ قَالَ مُوسَىٰ لِقَوْمِهِ يَا قَوْمِ لِمَ تُؤْذُونَنِي وَقَدْ تَعْلَمُونَ أَنِّي رَسُولُ اللَّهِ إِلَيْكُمْ\n",
            "==========\n",
            "Input: \n",
            "ولله يسجد ما في السماوات وما في الارض من دابة والملاءكة وهم لا يستكبرون\n",
            "==========\n",
            "Prediction: \n",
            "وَلِلَّهِ يَسْجُدُ مَا فِي السَّمَاوَاتِ وَمَا فِي الْارْضِ مِنْ دَابَّةٍ وَالْمَلَائِكَةُ وَهُمْ لَا يَسْتَكْبِرُونَ\n",
            "==========\n",
            "Input: \n",
            "الذي أحسن كل شيء خلقه وبدأ خلق الإنسان من طين\n",
            "==========\n",
            "Prediction: \n",
            "الَّذِي أَحْسَنَ كُلَّ شَيْءٍ خَلْقَهُ وَبَدَأَ خَلْقَ الْإِنْسَانِ مِنْ طِينٍ\n",
            "==========\n",
            "=============== Hadith Texts ===============\n",
            "Input: \n",
            "إن الله لا ينظر إلى صوركم وأموالكم ولكن ينظر إلى قلوبكم وأعمالكم\n",
            "==========\n",
            "Prediction: \n",
            "إِنَّ اللَّهَ لَا يَنْظُرُ إِلَىٰ صُوَرِكُمْ وَأَمْوَالِكُمْ وَلَكِنْ يَنْظُرُ إِلَىٰ قُلُوبِكُمْ وَأَعْمَالِكُمْ\n",
            "==========\n",
            "Input: \n",
            "عن أبي ذر جندب بن جنادة، وأبي عبدالرحمن معاذ بن جبل رضي الله عنهما، عن رسول الله ﷺ، قال: اتق الله حيثما كنت وأتبع السيئة الحسنة تمحها، وخالق الناس بخلق حسن . رواه الترمذي وقال: حديث حسن.\n",
            "==========\n",
            "Prediction: \n",
            "عَنْ أَبِي ذَرٍّ جُنْدُبِ بْنِ جُنَادَةَ، وَأَبِي عَبْدِالرَّحْمَنِ مُعَاذِ بْنِ جَبَلٍ رَضِيَ اللَّهُ عَنْهُمَا، عَنْ رَسُولِ اللَّهِ صَلَّى اللَّهُ عَلَيْهِ وَسَلَّمَ، قَالَ: اتَّقِ اللَّهَ حَيْثُمَا كُنْتَ وَأَتْبِعِ السَّيِّئَةَ الْحَسَنَةَ تَمْحُهَا، وَخَالِقِ النَّاسَ بِخُلُقٍ حَسَنٍ . رَوَاهُ التِّرْمِذِيُّ وَقَالَ: حَدِيثٌ حَسَنٌ.\n",
            "==========\n",
            "Input: \n",
            "المسلم من سلم المسلمون من لسانه ويده\n",
            "==========\n",
            "Prediction: \n",
            "الْمُسْلِمُ مَنْ سَلِمَ الْمُسْلِمُونَ مِنْ لِسَانِهِ وَيَدِهِ\n",
            "==========\n",
            "Input: \n",
            "المؤمن القوي خير وأحب إلى الله من المؤمن الضعيف ، وفي كل خير.\n",
            "==========\n",
            "Prediction: \n",
            "الْمُؤْمِنُ الْقَوِيُّ خَيْرٌ وَأَحَبُّ إِلَى اللَّهِ مِنَ الْمُؤْمِنِ الضَّعِيفِ ، وَفِي كُلِّ خَيْرٍ.\n",
            "==========\n",
            "=============== Arabic Texts ===============\n",
            "Input: \n",
            "إنما الأمم الأخلاق ما بقيت فإن هم ذهبت أخلاقهم ذهبوا\n",
            "==========\n",
            "Prediction: \n",
            "إِنَّمَا الأُمَمُ الأَخْلاقُ مَا بَقِيَتْ فَإِنْ هُمْ ذَهَبَتْ أَخْلاقُهُمْ ذَهَبُوا\n",
            "==========\n",
            "Input: \n",
            "يعد من أكبر علماء الأندلس وأكبر علماء الإسلام تصنيفًا وتأليفًا بعد الطبري، وهو إمام حافظ. فقيه ظاهري، ومجدد القول به، بل محيي المذهب بعد زواله في الشرق. ومتكلم وأديب وشاعر ونسّابة وعالم برجال الحديث وناقد محلل بل وصفه البعض بالفيلسوف كما عد من أوائل من قال بكروية الأرض، كما كان وزير سياسي لبني أمية، سلك طريق نبذ التقليد وتحرير الأتباع، قامت عليه جماعة من المالكية وشـُرد عن وطنه. توفي لاحقاً في منزله في أرض أبويه منت ليشم المعروفة بمونتيخار حالياً، وهي عزبة قريبة من ولبة. وأصل جده يزيد فارسي، أسلم وأول من دخل منهم بلاد المغرب، وكانت بلدهم قرطبة فولد ابن حزم بها في سلخ نهاية رمضان من سنة أربع وثمانين وثلاثمائة.\n",
            "==========\n",
            "Prediction: \n",
            "يُعَدُّ مِنْ أَكْبَرِ عُلَمَاءِ الْأَنْدَلُسِ وَأَكْبَرِ عُلَمَاءِ الْإِسْلَامِ تَصْنِيفًا وَتَأْلِيفًا بَعْدَ الطَّبَرِيِّ، وَهُوَ إِمَامٌ حَافِظٌ. فَقِيهٌ ظَاهِرِيٌّ، وَمُجَدِّدُ الْقَوْلِ بِهِ، بَلْ مُحْيِي الْمَذْهَبِ بَعْدَ زَوَالِهِ فِي الشَّرْقِ. وَمُتَكَلِّمٌ وَأَدِيبٌ وَشَاعِرٌ وَنَسَّابَةٌ وَعَالِمٌ بِرِجَالِ الْحَدِيثِ وَنَاقِدٌ مُحَلَّلٌ بَلْ وَصَفَهُ الْبَعْضُ بِالْفَيْلَسُوفِ كَمَا عُدَّ مِنْ أَوَائِلِ مَنْ قَالَ بِكُرَوِيَّةِ الْأَرْضِ، كَمَا كَانَ وَزِيرٌ سِيَاسِيٌّ لِبَنِي أُمَيَّةَ، سَلَكَ طَرِيقَ نَبْذِ التَّقْلِيدِ وَتَحْرِيرَ الْأَتْبَاعِ، قَامَتْ عَلَيْهِ جَمَاعَةٌ مِنَ الْمَالِكِيَّةِ وَشَـرُّدٌ عَنْ وَطَنِهِ. تُوُفِّيَ لَاحِقًا فِي مَنْزِلِهِ فِي أَرْضِ أَبَوَيْهِ مُنْتَ لِيَشُمَّ الْمَعْرُوفَةَ بِمُونتِيخَارٍ حَالِيًّا، وَهِيَ عَزْبَةٌ قَرِيبَةٌ مِنْ وَلُبَّةٍ. وَأَصْلُ جَدِّهِ يَزِيدُ فَارِسِيٌّ، أَسْلَمَ وَأَوَّلُ مَنْ دَخَلَ مِنْهُمْ بِلَادَ الْمَغْرِبِ، وَكَانَتْ بَلَدُهُمْ قُرْطُبَةَ فَوُلِدَ ابْنُ حَزْمٍ بِهَا فِي سَلْخِ نِهَايَةِ رَمَضَانَ مِنْ سَنَةِ أَرْبَعٍ وَثَمَانِينَ وَثَلَاثِمِائَةٍ.\n",
            "==========\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = vocalize_text('وصار الوقت جاريًا في غيبتي # يدني النور والظلماء أمامي', model_tashkeel, tokenizer)\n",
        "sequence = [char2idx.get(char, 0) for char in sentence]\n",
        "sequence = pad_sequences([sequence], maxlen=X_train.shape[1], padding='post', value=0)\n",
        "pred = model.predict(sequence)[0]\n",
        "print(label2name[np.argmax(pred, 0).astype('int')], np.max(pred))"
      ],
      "metadata": {
        "id": "gqtzzlQ1rLX5",
        "outputId": "9c2a3dfe-eb5b-4744-ef90-06afc34fcecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "khafeef 0.7795467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classify(x)"
      ],
      "metadata": {
        "id": "brQyfLUcs7jz",
        "outputId": "a6d893d2-a935-4b5a-9da6-597383d539e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "khafeef 0.7795467\n"
          ]
        }
      ]
    }
  ]
}